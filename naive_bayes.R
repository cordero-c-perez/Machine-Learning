# naive_bayes for NYPD data


# clear global environment
rm(list = ls(all.names = TRUE))


# libraries
library(naivebayes)
library(tidyverse)
library(lubridate)
library(rgdal)


# import data
nb_data <- read_csv("~/Documents/R/RProjects-Public/Machine-Learning-Data/NYPD_Complaint_Data_Historic.csv",
                    col_names = TRUE)
ytd_data <- read_csv("~/Documents/R/RProjects-Public/Machine-Learning-Data/NYPD_Complaint_Data_YTD.csv",
                     col_names = TRUE) %>% select(c(1:35))

nb_data <- as.data.frame(rbind(nb_data,ytd_data))

my_spdf <- readOGR("~/Documents/R/RProjects-Public/Machine-Learning-Data/Police Precincts.geojson")

# take key columns for naive_bayes analysis: date (month, year), time, law_ct_code, borough,
nb_data <- nb_data %>% select(c(2,3,6,9,11:14,))


# cleaning & pre-processing
nb_data$CMPLNT_FR_DT <- as.Date(nb_data$CMPLNT_FR_DT, "%m/%d/%Y")
nb_data$CRM_ATPT_CPTD_CD <- as.factor(nb_data$CRM_ATPT_CPTD_CD)
nb_data$OFNS_DESC <- as.factor(nb_data$OFNS_DESC)
nb_data$PD_DESC <- as.factor(nb_data$PD_DESC)
nb_data$LAW_CAT_CD <- as.factor(nb_data$LAW_CAT_CD)
nb_data$BORO_NM <- as.factor(nb_data$BORO_NM)


# clean up strings
nb_data$OFNS_DESC <- str_replace(nb_data$OFNS_DESC, 
                                 "INTOXICATED/IMPAIRED DRIVING", "INTOXICATED & IMPAIRED DRIVING")

nb_data <- nb_data %>% mutate(Year = as.factor(year(nb_data$CMPLNT_FR_DT))) %>% 
  mutate(Month = as.factor(month(nb_data$CMPLNT_FR_DT, label = TRUE)))

timebin <- as.POSIXct(strptime(c("050000","105959","110000","165959","170000",
                        "235959", "240000", "045959"),"%H%M%S"),"UTC")

timetoday <- as.POSIXct(strptime(nb_data$CMPLNT_FR_TM,"%H:%M:%S"),"UTC")

nb_data$timenominal <- case_when(
  between(timetoday,timebin[1],timebin[2]) ~"Morning",
  between(timetoday,timebin[3],timebin[4]) ~"Afternoon",
  between(timetoday,timebin[5],timebin[6]) ~"Evening",
  is.na(timetoday) ~ "remove row",
  TRUE ~"Late Night")


colnames(nb_data) <- c("Date", "Time Numeric", "Precinct", "Offense Description", "PD Description", 
                       "Crime Status","Crime Category", "Borough", "Year", "Month", "Time")

# last minute conversions & cleaning
nb_data$Precinct <- as.factor(nb_data$Precinct)
nb_data$Time <- as.factor(nb_data$Time)

nb_data <- nb_data %>% filter(Time != "remove row") %>% # time not present in 48 records that are not valid
  filter(Precinct != "-99") %>% # Department of Corrections record = no valid precinct
  filter(!(is.na(Month))) # excludes 15 valid records that do not have a complnt fr date


# replace approx. 18,000 missing values in the offense description set by values in outside vector
# step 1: arrange values by pd description
nb_data <- nb_data %>% arrange(`PD Description`)

# step 2: create the hash map via two vectors
sample2 <- nb_data %>%
  group_by(`Offense Description`, `PD Description`) %>% 
  summarise(count = n()) %>% 
  arrange(`Offense Description`)

hash_map <- sample2[c(1:295,297:422),1:2] # used to recode the offense description NA values

# hash map recoding into new vector to double check values
vec <- nb_data$`PD Description`
vec_levels <- hash_map$`PD Description`
vec_labels <- hash_map$`Offense Description`

offdes2 <- vec_labels[match(vec,vec_levels)] # new vector to check against offense description vector

nb_data <- nb_data %>% 
  mutate(offdesc2 = offdes2) # adds new Offense Description vector to check against original

# replace the offense description vector with the new vector
nb_data <- nb_data %>% mutate(`Offense Description` = offdesc2) %>% select(-c("offdesc2")) %>% 
  droplevels()


################################# DATA CHECK AFTER PRE-PROCESSING ######################################

# quick view of data
view(head(nb_data, n = 20))
str(nb_data)

# export the dataset
write_csv(nb_data,"~/Documents/R/RProjects-Public/Machine-Learning-Data/cleaned_nb_data.csv")

################################### START OF NAIVE BAYES ###############################################

# restrict the timeframe
nb_data_list <- list(c(1:6))
nb_data_list[[1]] <- nb_data %>% filter(Date >= "2015-01-01" & Date <= "2015-12-31") %>% droplevels()
nb_data_list[[2]] <- nb_data %>% filter(Date >= "2016-01-01" & Date <= "2016-12-31") %>% droplevels()
nb_data_list[[3]] <- nb_data %>% filter(Date >= "2017-01-01" & Date <= "2017-12-31") %>% droplevels()
nb_data_list[[4]] <- nb_data %>% filter(Date >= "2018-01-01" & Date <= "2018-12-31") %>% droplevels()
nb_data_list[[5]] <- nb_data %>% filter(Date >= "2019-01-01" & Date <= "2019-12-31") %>% droplevels()
nb_data_list[[6]] <- nb_data %>% filter(Date >= "2020-01-01" & Date <= "2020-12-31") %>% droplevels()

# build model for each year probabilities
# Run the naive bayes model: Crime Category ~ 
nb_models_list <- list(c(1:6))

for (i in 1:6){
nb_models_list[[i]] <- naive_bayes(formula = `Offense Description` ~ Precinct+Month+Time, 
                              data = nb_data_list[[i]], laplace = 1)
}

# saved data files for shiny app
saveRDS(nb_models_list, file = "datamodels.rds")
saveRDS(nb_data[,3:11], file = "nbdata.rds")
saveRDS(my_spdf, file = "spdf.rds")


prior_probs <- c()
for (i in 1:5){
  prior_probs <- rbind(prior_probs,nb_models_list[[i]]$prior)
}

# create data frame
prior_probs <- as.data.frame(cbind(Year = c(2015:2019), prior_probs))
prior_probs$Year <- as.factor(prior_probs$Year)
prior_probs <- gather(data = prior_probs, key = `Crime Category`, value = "Probability",-Year)


########################################## Notes

# construct test data frame

test_df <- nb_data[23000,c(3,10:11)]
colnames(test_df) <- c("Precinct", "Month", "Time")


# Make prediction given NB model
output <- predict(nb_models_list[[3]], newdata =  test_df, type = "prob")

tester <- as.data.frame(cbind(dimnames(output)[[2]],output[1,]))
rownames(tester) <- NULL
names(tester) <- c("Offense Description", "Probability")
tester$Probability <- as.numeric(tester$Probability)
tester <- tester %>% arrange(desc(Probability))


nb_multi_model















